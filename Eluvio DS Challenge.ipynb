{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dfply import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To convert the sentences\n",
    "# The method is the universal sentence encoder: https://arxiv.org/abs/1803.11175\n",
    "module_url = \"https://tfhub.dev/google/universal-sentence-encoder-large/3\"\n",
    "# Import the Universal Sentence Encoder's TF Hub module\n",
    "embed = hub.Module(module_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encoding function\n",
    "def onehot_encoder(data):\n",
    "    YY = np.zeros((len(data), 2))\n",
    "    YY[np.arange(len(data)), data] = 1\n",
    "    return YY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the universal sentence encoder function\n",
    "def USencoder(l):\n",
    "    with tf.Session() as session:\n",
    "        session.run([tf.global_variables_initializer(), tf.tables_initializer()])\n",
    "        message_embeddings = session.run(embed(l))\n",
    "        return message_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "df = pd.read_csv('Eluvio_DS_Challenge.csv')\n",
    "# only keep the column up_votes and the title\n",
    "df = df>> select(X.up_votes,X.title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class the data into two groups: with threshold as the 80% of the up_votes\n",
    "# if up_votes number > threshold is an attractive news; o.w. it is not an attractive news\n",
    "threshold = np.quantile( df['up_votes'], 0.7) # corresponding value is 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df >> mutate(category = (X.up_votes>threshold)*1 ) >> \\\n",
    "     mutate(sample_weight = case_when([X.category == 0, 0.3],[X.category == 1, 0.7]))\n",
    "\n",
    "print('The number of the attractive news', sum(df['category']), '; the number of the non-attractive news', len(df)-sum(df['category']),'.')\n",
    "\n",
    "\n",
    "np.random.seed(seed=1)\n",
    "score = pd.DataFrame(np.random.randn(df.shape[0], 1))\n",
    "msk = np.random.rand(len(score)) < 0.99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df[msk]\n",
    "test = df[~msk]\n",
    "\n",
    "print('The number of the training data is ', len(train), '; the number of the testing data', len(test),'.')\n",
    "\n",
    "# # convert the testing data and save them\n",
    "# test_text = test['title'].values.tolist()\n",
    "#\n",
    "# with tf.Session() as session:\n",
    "#   session.run([tf.global_variables_initializer(), tf.tables_initializer()])\n",
    "#   message_embeddings = session.run(embed(test_text))\n",
    "#   np.savetxt('covariate.csv',message_embeddings, delimiter=',')\n",
    "\n",
    "# test_x = message_embeddings\n",
    "test_x = np.loadtxt('covariate.csv',delimiter = ',')\n",
    "test_y = test['category'].values.tolist()\n",
    "print('The proportion of the attractive news in testing data is ', sum(test_y)/len(test_y),'.')\n",
    "test_y = onehot_encoder(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dnn(x):\n",
    "    with tf.name_scope('layer_1'):\n",
    "        W_1 = weight_variable([512,256])\n",
    "        b_1 = bias_variable([256])\n",
    "        h_1 = tf.nn.relu(tf.matmul(x, W_1) + b_1)\n",
    "\n",
    "    with tf.name_scope('layer_2'):\n",
    "        W_2 = weight_variable([256,128])\n",
    "        b_2 = bias_variable([128])\n",
    "        h_2 = tf.nn.relu(tf.matmul(h_1, W_2) + b_2)\n",
    "\n",
    "    with tf.name_scope('layer_3'):\n",
    "        W_3 = weight_variable([128,64])\n",
    "        b_3 = bias_variable([64])\n",
    "        h_3 = tf.nn.relu(tf.matmul(h_2, W_3) + b_3)\n",
    "\n",
    "    with tf.name_scope('dropout'):\n",
    "        rate = tf.placeholder(tf.float32)\n",
    "        h_3_drop = tf.nn.dropout(h_3, rate = rate)\n",
    "\n",
    "    with tf.name_scope('full_connected'):\n",
    "        W_4 = weight_variable([64, 2])\n",
    "        b_4 = bias_variable([2])\n",
    "        y_pred = tf.nn.relu(tf.matmul(h_3_drop, W_4) + b_4)\n",
    "\n",
    "    return y_pred, rate\n",
    "\n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev= 0.1)\n",
    "    return tf.Variable(initial, name = 'W')\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(.1, shape = shape)\n",
    "    return tf.Variable(initial, name = 'b')\n",
    "\n",
    "def main():\n",
    "    tf.set_random_seed(1)\n",
    "\n",
    "    x = tf.placeholder(tf.float32, [None, 512])  # our covariate is 512 dimensional\n",
    "    y = tf.placeholder(tf.float32, [None, 2])  # 2 classes\n",
    "\n",
    "    y_pred , rate = dnn(x)\n",
    "\n",
    "    with tf.name_scope('Loss'):\n",
    "        cross_entropy = tf.nn.softmax_cross_entropy_with_logits_v2(labels= y, logits= y_pred)\n",
    "        cross_entropy = tf.reduce_mean(cross_entropy)\n",
    "\n",
    "    with tf.name_scope('adam_optimizer'):\n",
    "        train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "\n",
    "    with tf.name_scope('Average_Accuracy'):\n",
    "        correct_prediction = tf.cast(tf.equal(tf.argmax(y_pred, 1), tf.argmax(y, 1)), tf.float32)\n",
    "        accuracy = tf.reduce_mean(correct_prediction)\n",
    "\n",
    "    with tf.name_scope('True_Positive'):\n",
    "        tp = tf.reduce_sum(tf.argmax(y_pred, 1) * tf.argmax(y, 1))/ tf.reduce_sum(tf.argmax(y, 1))\n",
    "\n",
    "    with tf.name_scope('True_Negative'):\n",
    "        tn = tf.reduce_sum((1-tf.argmax(y_pred, 1)) * (1-tf.argmax(y, 1)))/ tf.reduce_sum(1-tf.argmax(y, 1))\n",
    "\n",
    "    trainwriter = tf.summary.FileWriter('./dnn/train')\n",
    "    testwriter = tf.summary.FileWriter('./dnn/test')\n",
    "    trainwriter.add_graph(tf.get_default_graph())\n",
    "    tf.summary.scalar('Prediction_Accuracy', accuracy)\n",
    "    tf.summary.scalar('Objective_Loss', cross_entropy)\n",
    "    tf.summary.scalar('Pred_True_Positive', tp)\n",
    "    tf.summary.scalar('Pred_True_Negative', tn)\n",
    "    s = tf.summary.merge_all()\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        # Training cycle\n",
    "        for epoch in range(100):\n",
    "            batch_train_df = train.sample(64, weights= 'sample_weight')\n",
    "            batch_ys = onehot_encoder(batch_train_df['category'].values.tolist())\n",
    "            batch_xs = USencoder(batch_train_df['title'].values.tolist())\n",
    "\n",
    "            train_step.run(feed_dict={x: batch_xs, y: batch_ys, rate: 0.5})\n",
    "            train_summary = sess.run(s, feed_dict={x: batch_xs, y: batch_ys, rate: 0})\n",
    "            trainwriter.add_summary(train_summary, epoch)\n",
    "\n",
    "            test_summary = sess.run(s, feed_dict={x: test_x, y: test_y, rate: 0})\n",
    "            testwriter.add_summary(test_summary, epoch)\n",
    "\n",
    "            train_accuracy = accuracy.eval(feed_dict={x: batch_xs, y: batch_ys, rate: 0})\n",
    "            print('step %d, training accuracy %g' % (epoch, train_accuracy))\n",
    "\n",
    "\n",
    "        trainwriter.close()\n",
    "        testwriter.close()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
